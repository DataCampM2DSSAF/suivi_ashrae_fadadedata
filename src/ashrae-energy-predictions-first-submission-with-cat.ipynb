{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "First submission :\n",
    "\n",
    "<a href='#1'>1. Loading Data</a>\n",
    "\n",
    "<a href='#2'>2. Combining Datasets</a>\n",
    "\n",
    "<a href='#3'>3. Memory Limitation</a>\n",
    "\n",
    "<a href='#4'>4. Missing Values</a>\n",
    "\n",
    "<a href='#5'>5.EDA</a>\n",
    "\n",
    "<a href='#6'>6. Model Training</a>\n",
    "\n",
    "<a href='#7'>7. Model Predictions and Kaggle Submission</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='1'>1. Loading Data</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load data\n",
    "train = pd.read_csv('kaggle/input/ashrae-energy-prediction/train.csv')\n",
    "train['timestamp'] = pd.to_datetime(train['timestamp']) #the train dataset contains a 'timestamp' column we convert to a datetime object for ease of use\n",
    "test = pd.read_csv('kaggle/input/ashrae-energy-prediction/test.csv')\n",
    "test['timestamp'] = pd.to_datetime(test['timestamp'])\n",
    "weather_train = pd.read_csv('kaggle/input/ashrae-energy-prediction/weather_train.csv')\n",
    "weather_train['timestamp'] = pd.to_datetime(weather_train['timestamp']) \n",
    "weather_test = pd.read_csv('kaggle/input/ashrae-energy-prediction/weather_test.csv')\n",
    "weather_test['timestamp'] = pd.to_datetime(weather_test['timestamp']) \n",
    "build_meta = pd.read_csv('kaggle/input/ashrae-energy-prediction/building_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a simple first model, we are going to merge the training sets to gather all covariables and make predictions on it with a linear regressor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='2'>2. Combining Datasets</a>\n",
    "We will merge everything into train and test dataframes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to convert the timestamp to the right type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather_test.timestamp = pd.to_datetime(weather_test.timestamp) \n",
    "weather_train.timestamp = pd.to_datetime(weather_train.timestamp) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the building meta data and weather data into the train data\n",
    "train_m = train.merge(build_meta, how='left', on = ['building_id'], validate='many_to_one') #merge the building meta data into the train data\n",
    "test_m = test.merge(build_meta, how='left', on = ['building_id'], validate='many_to_one') #merge the building meta data into the train data\n",
    "train_m = train_m.merge(weather_train, how='left', on = ['site_id', 'timestamp'], validate='many_to_one')#add weather data to each time entry for each site ID\n",
    "test_m = test_m.merge(weather_test, how='left', on = ['site_id', 'timestamp'], validate='many_to_one')#add weather data to each time entry for each site ID\n",
    "del build_meta, weather_train, weather_test\n",
    "import gc\n",
    "gc.collect() #mandatory since we don't have unlimited space (16go and the databases are quite large)\n",
    "train_m.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='3'>3. Memory Limitation</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True): #we need to drastically reduce memory usage to work with those data basis\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df\n",
    "\n",
    "train_m = reduce_mem_usage(train_m) #this code changes the variable formats so it takes less space\n",
    "test_m = reduce_mem_usage(test_m) #source for this code : https://www.kaggle.com/alexandersylvester/ashrae-energy-predictions-with-lightgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='4'>4. Missing Values</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_m.isna().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_m.isna().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The easy way out in this scenario is to drop the columns containing any NA. Which we're going to do for the time being. We have no missing value for the target variable so we will not be dropping any training row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_m = train_m.dropna(axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gc.collect(generation=0)\n",
    "gc.collect(generation=1)\n",
    "gc.collect() #supposedly cleans the memory but not that efficient // we need a better way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_m = test_m.dropna(axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_m.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_m.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_m.groupby(\"primary_use\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_m.primary_use = train_m.primary_use.astype('category')\n",
    "test_m.primary_use = test_m.primary_use.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dr = test_m.primary_use\n",
    "# test_m = test_m.drop('primary_use',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dr2 = train_m.primary_use\n",
    "# train_m = train_m.drop('primary_use',axis=1)\n",
    "## train_m = train_m.drop('meter_reading',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_m.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_m.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = train_m\n",
    "test_df = test_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "train_df['month_datetime'] = train_df['timestamp'].dt.month.astype(np.int8)\n",
    "train_df['weekofyear_datetime'] = train_df['timestamp'].dt.weekofyear.astype(np.int8)\n",
    "train_df['dayofyear_datetime'] = train_df['timestamp'].dt.dayofyear.astype(np.int16)\n",
    "    \n",
    "train_df['hour_datetime'] = train_df['timestamp'].dt.hour.astype(np.int8)  \n",
    "train_df['day_week'] = train_df['timestamp'].dt.dayofweek.astype(np.int8)\n",
    "train_df['day_month_datetime'] = train_df['timestamp'].dt.day.astype(np.int8)\n",
    "train_df['week_month_datetime'] = train_df['timestamp'].dt.day/7\n",
    "train_df['week_month_datetime'] = train_df['week_month_datetime'].apply(lambda x: math.ceil(x)).astype(np.int8)\n",
    "    \n",
    "# train_df['year_built'] = train_df['year_built']-1900\n",
    "train_df['square_feet'] = np.log(train_df['square_feet'])\n",
    "    \n",
    "test_df['month_datetime'] = test_df['timestamp'].dt.month.astype(np.int8)\n",
    "test_df['weekofyear_datetime'] = test_df['timestamp'].dt.weekofyear.astype(np.int8)\n",
    "test_df['dayofyear_datetime'] = test_df['timestamp'].dt.dayofyear.astype(np.int16)\n",
    "    \n",
    "test_df['hour_datetime'] = test_df['timestamp'].dt.hour.astype(np.int8)\n",
    "test_df['day_week'] = test_df['timestamp'].dt.dayofweek.astype(np.int8)\n",
    "test_df['day_month_datetime'] = test_df['timestamp'].dt.day.astype(np.int8)\n",
    "test_df['week_month_datetime'] = test_df['timestamp'].dt.day/7\n",
    "test_df['week_month_datetime'] = test_df['week_month_datetime'].apply(lambda x: math.ceil(x)).astype(np.int8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='5'>5. EDA</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_coorr=train_m.corr()\n",
    "sn.heatmap(mat_coorr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pas de corrélation particulière entre `meter_reading` et les autres variables. Il y a cependant quelques corrélations entre certaines variables comme `floor_count` et `square_feet` ou `air_temperature` et `dew_temperature`. nous les traiterons plus tard pour voir si ces corrélations ont une influence sur nos modèles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_na=train_m.isnull().sum()*100/train_m.shape[0]\n",
    "is_na=is_na.sort_values()\n",
    "ind = np.arange(len(is_na))\n",
    "plt.bar(ind, is_na.values)\n",
    "plt.xticks(ind,is_na.index,rotation=90)\n",
    "plt.ylabel(\"Pourcentage de NA\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les labels `floor_count` et `year_built` sont ceux pour lesquels il y a le plus de NA. C'est dommage car ce sont des indexs qui intuitivement auront beaucoup d'influence sur l'energie consommée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 1, figsize=(14, 6),dpi=100)\n",
    "train_m[['timestamp', 'meter_reading']].set_index('timestamp').resample('H').mean()['meter_reading'].plot(ax=axes, label='Par heure').set_ylabel('Meter reading');\n",
    "train_m[['timestamp', 'meter_reading']].set_index('timestamp').resample('D').mean()['meter_reading'].plot(ax=axes, label='Par jour').set_ylabel('Meter reading');\n",
    "axes.set_title('Metre relevé moyen par jour et par heure');\n",
    "axes.legend();\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La forme de la distribution de la valeur cible dans le temps est plutôt étrange. On observe des pics irréguliers. Regardons de plus près."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(8,2,figsize=(14, 30), dpi=100)\n",
    "list_pu=list(train_m['primary_use'].value_counts().index);\n",
    "for i in range(len(list_pu)):\n",
    "    train_m[train_m['primary_use'] == list_pu[i]][['timestamp', 'meter_reading']].set_index('timestamp').resample('H').mean()['meter_reading'].plot(ax=axes[i%8][i//8], label='Par heure').set_ylabel('Metre relevé moyen');\n",
    "    train_m[train_m['primary_use'] == list_pu[i]][['timestamp', 'meter_reading']].set_index('timestamp').resample('D').mean()['meter_reading'].plot(ax=axes[i%8][i//8],  label='Par jour').set_xlabel('');\n",
    "    axes[i%8][i//8].legend();\n",
    "    axes[i%8][i//8].set_title(list_pu[i]);\n",
    "    plt.subplots_adjust(hspace=0.45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notre problème se situe dans Education."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(8,2,figsize=(14, 30), dpi=100)\n",
    "list_sid=list(train_m['site_id'].value_counts().index);\n",
    "train_hist=train_m[train_m['primary_use'] == 'Education']\n",
    "for i in range(len(list_sid)):\n",
    "    try :\n",
    "        train_hist[train_hist['site_id'] == i][['timestamp', 'meter_reading']].set_index('timestamp').resample('H').mean()['meter_reading'].plot(ax=axes[i%8][i//8], label='Par heure').set_ylabel('Metre relevé moyen');\n",
    "        train_hist[train_hist['site_id'] == i][['timestamp', 'meter_reading']].set_index('timestamp').resample('D').mean()['meter_reading'].plot(ax=axes[i%8][i//8],  label='Par jour').set_xlabel('');\n",
    "        axes[i%8][i//8].legend();\n",
    "    except :\n",
    "        pass\n",
    "    axes[i%8][i//8].set_title(i);\n",
    "    plt.subplots_adjust(hspace=0.45)\n",
    "plt.show()\n",
    "del train_hist;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notre problème se situe dans le 13."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3,1,figsize=(14, 18), dpi=100)\n",
    "train_hist=train_m[train_m['primary_use'] == 'Education']\n",
    "train_hist2=train_hist[train_hist['site_id'] == 13]\n",
    "list_met=list(train_hist2['meter'].value_counts().index);\n",
    "for i in range(len(list_met)):\n",
    "    try :\n",
    "        train_hist2[train_hist2['meter'] == list_met[i]][['timestamp', 'meter_reading']].set_index('timestamp').resample('H').mean()['meter_reading'].plot(ax=axes[i], label='Par heure').set_ylabel('Metre relevé moyen');\n",
    "        train_hist2[train_hist2['meter'] == list_met[i]][['timestamp', 'meter_reading']].set_index('timestamp').resample('D').mean()['meter_reading'].plot(ax=axes[i],  label='Par jour').set_xlabel('');\n",
    "        axes[i].legend();\n",
    "    except TypeError:\n",
    "        pass\n",
    "    axes[i].set_title(list_met[i]);\n",
    "    plt.subplots_adjust(hspace=0.45)\n",
    "plt.show()\n",
    "del train_hist;\n",
    "del train_hist2;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le problème se situe dans le metre de type 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(9,2,figsize=(14, 36), dpi=100)\n",
    "train_hist=train_m[train_m['primary_use'] == 'Education']\n",
    "train_hist2=train_hist[train_hist['site_id'] == 13]\n",
    "train_hist3=train_hist2[train_hist2['meter']==2]\n",
    "list_build=list(train_hist3['building_id'].value_counts().index);\n",
    "for i in range(len(list_build)):\n",
    "    try :\n",
    "        train_hist3[train_hist3['building_id'] == list_build[i]][['timestamp', 'meter_reading']].set_index('timestamp').resample('H').mean()['meter_reading'].plot(ax=axes[i%9][i//9], label='Par heure').set_ylabel('Metre relevé moyen');\n",
    "        train_hist3[train_hist3['building_id'] == list_build[i]][['timestamp', 'meter_reading']].set_index('timestamp').resample('D').mean()['meter_reading'].plot(ax=axes[i%9][i//9],  label='Par jour').set_xlabel('');\n",
    "        axes[i%9][i//9].legend();\n",
    "    except TypeError:\n",
    "        pass\n",
    "    axes[i%9][i//9].set_title(list_build[i]);\n",
    "    plt.subplots_adjust(hspace=0.45)\n",
    "plt.show()\n",
    "del train_hist;\n",
    "del train_hist2;\n",
    "del train_hist3;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 1, figsize=(14, 6),dpi=100)\n",
    "train_m[['timestamp', 'meter_reading']].set_index('timestamp').resample('H').mean()['meter_reading'].plot(ax=axes, label='Par heure').set_ylabel('Meter reading');\n",
    "train_m[['timestamp', 'meter_reading']].set_index('timestamp').resample('D').mean()['meter_reading'].plot(ax=axes, label='Par jour').set_ylabel('Meter reading');\n",
    "axes.set_title('Metre relevé moyen par jour et par heure');\n",
    "axes.legend();\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 1, figsize=(14, 6),dpi=100)\n",
    "new_train=train_m[train_m['building_id'] != 1099]\n",
    "new_train[['timestamp', 'meter_reading']].set_index('timestamp').resample('H').mean()['meter_reading'].plot(ax=axes, label='Par heure').set_ylabel('Meter reading');\n",
    "new_train[['timestamp', 'meter_reading']].set_index('timestamp').resample('D').mean()['meter_reading'].plot(ax=axes, label='Par jour').set_ylabel('Meter reading');\n",
    "axes.set_title('Metre relevé moyen par jour et par heure');\n",
    "axes.legend();\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remplacement NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in list_pu:\n",
    "    print(i)\n",
    "    print(new_train[new_train['primary_use']==i].isnull().sum()*100/new_train[new_train['primary_use']==i].shape[0])\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Services`, `Food sales and service`, `Religious worship` n'ont aucune donnée pour la variable `floor_count`. Nous allons d'abord combler ce qu'il manque dans les autres catégories par la moyenne. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "list_pu_mean=[]\n",
    "for i in list_pu:\n",
    "    list_pu_mean.append(statistics.mean(new_train[new_train['primary_use']==i].notnull()['floor_count']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='6'>6. Model Training</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import GridSearchCV #, train_test_split,TimeSeriesSplit\n",
    "from sklearn.metrics import make_scorer, mean_squared_error, mean_absolute_error, mean_squared_log_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "y_train = train_m['meter_reading']\n",
    "\n",
    "# my_tree = DecisionTreeRegressor()\n",
    "\n",
    "# MSE = make_scorer(mean_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# param_grid = {'splitter' : ['best', 'random'],'criterion' : ['mse', 'friedman_mse', 'mae', 'poisson']}\n",
    "# model = GridSearchCV(my_tree, param_grid, scoring=MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = train_df.drop('timestamp', axis = 1)\n",
    "\n",
    "test_df = test_df.drop('timestamp', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predicted = model.predict(test_df)\n",
    "\n",
    "# print('Best Parameters found for MSE : ',model.best_params_)\n",
    "# print('Train Score : ',model.score(train_m.drop('meter_reading') , y_train))\n",
    "\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from math import sqrt\n",
    "\n",
    "X = train_df\n",
    "X_test = test_df\n",
    "y = y_train\n",
    "\n",
    "reg = tree.DecisionTreeRegressor(max_leaf_nodes=50)\n",
    "reg = reg.fit(X,y)\n",
    "y_train_predict_tree=reg.predict(X)\n",
    "\n",
    "print(\"La RMSE de l'arbre de régression de train\",sqrt(mean_squared_error(y, y_train_predict_tree)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"La RMSLE de l'arbre de régression de train\",sqrt(mean_squared_log_error(y, y_train_predict_tree)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have tuned the model parameters and have an idea of model performance. We will fit on the entire training dataset so we have as much information as possible for the final test set prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='7'>7. Model Predictions and Kaggle Submission</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#obtention des prédictions et du fichier à évaluer \n",
    "y_test_predict_tree=reg.predict(X_test)\n",
    "\n",
    "my_submission = pd.DataFrame({'row_id': test_m.row_id, 'meter_reading': y_test_predict_tree})\n",
    "my_submission.to_csv('submission_tree_f.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

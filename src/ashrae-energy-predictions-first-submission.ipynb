{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introduction\n\nFirst submission :\n\n<a href='#1'>1. Loading Data</a>\n\n<a href='#2'>2. Combining Datasets</a>\n\n<a href='#3'>3. Missing Values</a>\n\n<a href='#4'>4. Model Training</a>\n\n<a href='#5'>5. Model Predictions</a>"},{"metadata":{},"cell_type":"markdown","source":"# <a id='1'>1. Loading Data</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#import libraries\nimport pandas as pd\nimport numpy as np\nimport sklearn as sk\nimport missingno as msno \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pickle","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#load data\ntrain = pd.read_csv('/kaggle/input/ashrae-energy-prediction/train.csv')\ntrain['timestamp'] = pd.to_datetime(train['timestamp']) #the train dataset contains a 'timestamp' column we convert to a datetime object for ease of use\ntest = pd.read_csv('/kaggle/input/ashrae-energy-prediction/test.csv')\ntest['timestamp'] = pd.to_datetime(test['timestamp'])\nweather_train = pd.read_csv('/kaggle/input/ashrae-energy-prediction/weather_train.csv')\nweather_test = pd.read_csv('/kaggle/input/ashrae-energy-prediction/weather_test.csv')\nbuild_meta = pd.read_csv('/kaggle/input/ashrae-energy-prediction/building_metadata.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For a simple first model, we are going to merge the training sets to gather all covariables and make predictions on it with a linear regressor."},{"metadata":{},"cell_type":"markdown","source":"# <a id='2'>2. Combining Datasets</a>\nWe will merge everything into train and test dataframes."},{"metadata":{"trusted":true},"cell_type":"code","source":"#merge the building meta data and weather data into the train data\ntrain_m = train.merge(build_meta, how='left', on = ['building_id'], validate='many_to_one') #merge the building meta data into the train data\ntrain_m = train_m.merge(weather_train, how='left', on = ['site_id', 'timestamp'], validate='many_to_one')#add weather data to each time entry for each site ID\n\n#merge the building meta data and weather data into the test data\ntest_m = test.merge(build_meta, how='left', on = ['building_id'], validate='many_to_one') #merge the building meta data into the train data\ntest_m = test_m.merge(weather_test, how='left', on = ['site_id', 'timestamp'], validate='many_to_one')#add weather data to each time entry for each site ID\n\ntrain_m.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <a id='3'>3. Missing Values</a>"},{"metadata":{},"cell_type":"markdown","source":"The linear regressor does not work with NA values. To make it simple to understand, we decided to use the simple imputer with the 'most frequent' method which replaces NA values with the modal value."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_m.dropna()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_m.isna().describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <a id='7'>7. Model Training</a>"},{"metadata":{},"cell_type":"markdown","source":"Below we will tune the model parameters and get an idea of how well the model can perform on unseen data. We have done this by:\n\n* Holding out the last 2.5 months of data for validation\n* Holding out 10% of the buildings for validation\n* Cross-validating time-series wise (for parameter tuning)\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nfrom sklearn.model_selection import train_test_split, GridSearchCV, TimeSeriesSplit\nfrom lightgbm import LGBMRegressor\nfrom sklearn.metrics import make_scorer, mean_squared_error, mean_absolute_error, mean_squared_log_error\n\n#defining a couple of functions for later use\ndef clip(x):\n    return np.clip(x, a_min=0, a_max=None)\ndef rmse(y, y_pred):\n    out = np.sqrt(mean_squared_error(clip(y), clip(y_pred)))\n    return out\n\n#prepare training data\nX = train_m.dropna(subset=['meter_reading']) #drop all rows where the meter reading is not included\nX = X.sort_values(by=['timestamp'], axis=0) #ensure X is sorted by timstamp for later timeseries cross-validation\n\nbuilds = X['building_id'].unique()#array of building ids in the dataset\nbuild_train, build_val = train_test_split(builds, test_size = 0.1, random_state=0)#hold out 10% of the buildings for validation\n\ntrain = X.loc[(X['timestamp']<'2016-10-15') \n          & (X['building_id'].isin(build_train))] #we will train on only the first 80% of the year and 90% buildings\nval_t = X.loc[(X['timestamp']>='2016-10-15') & (X['building_id'].isin(build_train))] #rest of the year and same buildings as above\nval_b = X.loc[(X['building_id'].isin(build_val))] #full year and the rest of the buildings\n\ny_train, y_val_t, y_val_b = train['meter_reading_rescaled'], val_t['meter_reading'], val_b['meter_reading'] #extracting the meter reading as our target variable\nX_train, X_val_t, X_val_b = train.drop(['meter_reading', 'meter_reading_rescaled', 'timestamp'], axis=1), val_t.drop(['meter_reading', 'meter_reading_rescaled','timestamp'], axis=1), val_b.drop(['meter_reading','meter_reading_rescaled','timestamp'], axis=1)\n\ndel X, train, val_t, val_b #no longer needed - free up memory\n\n# lgbm model\nmodel = LGBMRegressor(\nnum_leaves = 600,\nmin_data_in_leaf = 50,\nrandom_state = 0\n)\n\n#cross-validation for paramter tuning\n# params = {\n#     'num_leaves': [600],#add values to these lists to run a parmaeter optimization. These were found to be optimum.\n#          }\n\n# #define a rmse scorer for gridsearchcv\n# rmse_scorer = make_scorer(rmse, greater_is_better=False)\n# #split training data time series-wise for cross-validation\n# tscv = TimeSeriesSplit(n_splits=3)\n# #grid search\n# #Note that the scores given are based on the rescaled meter readings, so are not a direct representation of model performance\n# for model_name, grid in params.items():\n#     searchCV = GridSearchCV(model, scoring=rmse_scorer, cv=tscv, param_grid=params)\n#     print('GridSearchCV fitting...')\n#     searchCV.fit(X_train, y_train)\n#     scores = -1*searchCV.cv_results_['mean_test_score']\n#     params = searchCV.cv_results_['params']\n#     for i in range(0, len(scores)):\n#       print(params[i], '->', scores[i])\n\n#Evaluate combined model on the ramining validation data\nprint('Fitting...')\nmodel.fit(X_train, y_train)\n\nprint('Time predictions...')\npreds = clip(model.predict(X_val_t)) #make time predictions\npreds_inv = scaler.inverse_transform(X_val_t, np.expm1(preds)) #convert back to original scale, remembering to invert the log transform\ny_val_t = y_val_t.sort_index()\nscore = mean_absolute_error(preds_inv, y_val_t)\nprint('Mean absolute error - time prediction:', score)\nRMSLE = np.sqrt(mean_squared_log_error(preds_inv, y_val_t))\nprint('RMSLE - time prediction:', RMSLE)\n\nprint('Building predictions...')\npreds = clip(model.predict(X_val_b))\npreds_inv = scaler.inverse_transform(X_val_b, np.expm1(preds))\ny_val_b = y_val_b.sort_index()\nscore = mean_absolute_error(preds_inv, y_val_b)\nprint('Mean absolute error - new buildings:', score)\nRMSLE = np.sqrt(mean_squared_log_error(preds_inv, y_val_b))\nprint('RMSLE - new buildings:', RMSLE)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now that we have tuned the model parameters and have an idea of model performance. We will fit on the entire training dataset so we have as much information as possible for the final test set prediction."},{"metadata":{"trusted":true},"cell_type":"code","source":"#prepare training data\ntrain = train_m.dropna(subset=['meter_reading']) #drop all rows where the meter reading is not included\n\ny_train = train['meter_reading_rescaled'] #extracting the meter reading as our target variable\nX_train = train.drop(['meter_reading', 'meter_reading_rescaled', 'timestamp'], axis=1)\n\ndel train, train_m, X_val_t #no longer needed - free up memory\ngc.collect()\n\n#Fitting on all training data\nprint('Final Fitting...')\nmodel.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <a id='8'>8. Model Predictions</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#free up memory then load in the test data\ndel X_train, y_train\ngc.collect()\nX_test = pickle.load( open( \"test_m.p\", \"rb\" ) )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#output the final predictions on the test data to a csv file\npreds = np.empty(len(X_test))#we will predict in three steps to save memory\nprint('A')\npreds[:int(len(X_test)/3)] = model.predict(X_test.drop(['row_id', 'timestamp'], axis=1).iloc[:int(len(X_test)/3)])\npreds[int(len(X_test)/3):int(len(X_test)*2/3)] = model.predict(X_test.drop(['row_id', 'timestamp'], axis=1).iloc[int(len(X_test)/3):int(len(X_test)*2/3)])\npreds[int(len(X_test)*2/3):] = model.predict(X_test.drop(['row_id', 'timestamp'], axis=1).iloc[int(len(X_test)*2/3):])\nfinal_predictions = scaler.inverse_transform(X_test, np.expm1(preds))\nX_test = X_test.sort_index()\noutput = pd.DataFrame({'row_id': X_test['row_id'], 'meter_reading': clip(final_predictions)})\noutput['meter_reading'] = output['meter_reading'].round(decimals=4)#to save space\noutput.to_csv('sub.csv', index_label = 'row_id', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As a final check, we can plot the model predictions with the existing data for a specific building and meter type. Everything during 2016 is real data while the rest is our final predictions."},{"metadata":{"trusted":true},"cell_type":"code","source":"b_id = 400 #building id\nm_id = 0 #meter id\n\ntrain_m = pickle.load( open('train_m.p', 'rb'))\nbuilding_current = train_m.loc[(train_m['building_id']==b_id) & (train_m['meter']==m_id)]\nbuilding_forecast = X_test.loc[(X_test['building_id']==b_id) & (X_test['meter']==m_id)].merge(output, how='left', on = ['row_id'], validate='one_to_one')\nbuilding = pd.concat([building_current, building_forecast])\n\nX_o = building.drop(['meter_reading', 'row_id', 'timestamp', 'site_id'], axis=1)\ny_o = building['meter_reading']\n\nmod_plot = pd.DataFrame(data={#'meter_reading (predicted)':building_forecast['meter_reading'],\n                                    'meter_reading (actual and predicted)':y_o.values},\n                                    index=building['timestamp'])\nstart_time = '2016-01-01'\nend_time = '2019-01-01'\nmod_plot = mod_plot.loc[(start_time<mod_plot.index)&(mod_plot.index<end_time)].resample('D').mean()\nmod_plot.plot(rot=45)#plot each model vs target","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}